File Locations all team members need to know:
Tfrecords=/data/scripts/LES_TSI/SmallData/tfrecord/
	-If you want to add a tfrecord put it in its own folder, so they don't become jumbled.
Videos= /data/lasso/sims/20160611/18000
Unmasked Pictures= /data/scripts/LES_TSI/SmallData/inputs
Masked Pictures= /data/scripts/LES_TSI/SmallData/targets
Initial Checkpoints= /data/NeuralNetworkCheckpoints/Initial_Checkpoints/
	-Don't put anything but the initial checkpoints downloaded from the internet in here.
Checkpoints generated by train.py=/data/NeuralNetworkCheckpoints/Training_Generated_Checkpoints/
	-Created subfolders for everyone to keep things organized. As long as they are not corrupted we should all be able to use each other's.

README file

Self-study resources: 
Karpathy’s youtube lectures and syllabus
https://www.youtube.com/watch?v=i94OvYb6noo
http://cs231n.stanford.edu/2016/syllabus

Google AI Blog when DeepLab was released
https://ai.googleblog.com/2018/03/semantic-image-segmentation-with.html

What is Semantic Segmentation?
http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review

Original Deeplab paper
https://arxiv.org/pdf/1606.00915.pdf

What makes deeplab a good choice for semantic segmentation in English
https://sthalles.github.io/deep_segmentation_network/



Sources and purpose: 

The source code I am working with came from https://github.com/tensorflow/models/tree/master/research/deeplab.

Filenames and what they do and changes I made:

core/feature_extractor.py- Extracts features for different models. I am not currently using the mean_pixel() function, but I plan to in the future after getting train.py and some other stuff to to work.

core/preprocess_utils.py- flips,crops, pads, scales, resizes images
I have commented most of it out while I focus on getting train.py to work, but I am cropping most of the black of out the images. I think there might be a bug in the padding function.

datasets/build_clouds_data.py- Originally build_ade20k_data.py. Reads the data and converts to tfrecord. Replaced all mentions of ade20k to clouds and all jpg with png.

datasets/build_data.py- Contains functions called by build_clouds_data.py for building datasets and converting to tfrecord. I don’t think I made any significant changes to this file.

datasets/DatasetSplit.py- splits images and labels randomly into a training and test set before it is read and converted by build_clouds_data.py. I made this file, this is not an edited version of a deeplab file.

datasets/segmentation_dataset.py- Provides data from semantic segmentation datasets. Replaced all info about ade20k with clouds info.

utils/get_dataset_colormap.py- creates color map for dataset. Replaced info for ade20k with clouds info.

utils/input_generator.py- retrieves processed data for build_clouds_data.py. Don’t think I made significant changes.

utils/save_annotation.py- Saves an annotation as one png image. This script saves an annotation as one png image, and has the option to add colormap to the png image for better visualization. Haven’t touched yet.

utils/train_utils.py- Utility functions for training. One change to the exclude list was needed as listed here: https://gist.github.com/walkerlala/82d978e68407e65158e8825cd470d7e1

common.py- Flags that several files have in common. Set both aspp_with_batch_norm and aspp_with_seperable_conv to false to prevent a bug, but I might have to change them back in the future.

eval.py- evaluation script. Haven’t touched yet.

export_model.py- Exports trained model to TensorFlow frozen graph. Haven’t touched yet.

input_preprocess.py- Prepares the data used for DeepLab training/evaluation. Uses functions from preprocess_utils.py. Commented out the functions I am not using yet. Changed the inputs for the crop function and made sure reshaping worked. Tfrecord is a bytestream not an array so reshaping is important for creating tensors.

model.py- Provides DeepLab model definition and helper functions. Haven’t touched because it is a bad idea to. This is the reason I am using deeplab.

train.py- Trains the model. Changed some flags. Using xception instead of mobilenet_v2. Limited GPU use.

vis.py- Segmentation results visualization on a given set of images. Replaced info on dataset with info on clouds dataset.

To do for both train.py and vis.py:Tensorflow no longer supports train.supervisor, which is throwing an error in vis.py so replace with monitoredsession, which is actually supported and is more portable to different computers (important because if this works meteorologists/researchers will actively be using this).

How to run:

For all of these programs remember to fix any data paths that have changed before running.

Run /data/script/LES_TSI/sarahvtf.py to turn the videos that Nick’s program produces into pictures.

Run DataSplit.py to randomly separate the data into the training and test set.

Run build_clouds_data.py to turn data into a tfrecord.

Choose a model backbone. DeepLab supports several versions of resnet, mobile_net, and xception. I chose xception randomly from the models that threw the least errors when running in train.py. Make sure you have a checkpoint file for the version of the model you are using. The checkpoints are here https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md.The checkpoint file lists pretrained weights for your model to use as a starting point. During training you will unfreeze and retrain most of these weights. Only the first layer or so will remain frozen due to the dissimilarity between our very specific clouds dataset and  ImageNet or whatever set the model that produced the checkpoint was trained on. If they were similar more layers would stay frozen.

Run train.py with “python3 /data/tensorflow/models/research/deeplab/train.py --train_logdir=/data/tensorflow/models/research/deeplab/logdir/ --tf_initial_checkpoint=/data/tensorflow/models/research/deeplab/checkpoints/deeplabv3_xception_ade20k_train/model.ckpt.index –dataset_dir=/data/scripts/LES_TSI/SmallData/tfrecord/” in the command line to train the model on the data.

Sample commands to run from the terminal:

python3 /home/sarah/Documents/Repository/Cloud-Base-Detection/train.py --train_logdir=/home/sarah/Documents/Repository/Cloud-Base-Detection/logdir --tf_initial_checkpoint=/home/sarah/Documents/Repository/Cloud-Base-Detection/checkpoints/xception_71/model.ckpt --dataset_dir=/data/scripts/LES_TSI/SmallData/tfrecord/ &> outputfile.txt 

python3 /home/sarah/Documents/Repository/Cloud-Base-Detection/train/train.py --dataset_dir=/data/scripts/LES_TSI/SmallData/tfrecord/ --train_logdir=/home/sarah/Documents/Repository/Cloud-Base-Detection/train/logs

python3 /home/sarah/Documents/Repository/Cloud-Base-Detection/vis.py --checkpoint_dir=/home/sarah/Documents/Repository/Cloud-Base-Detection/logdir/ --vis_logdir=/home/sarah/Documents/Repository/Cloud-Base-Detection/vis_logdir/ --dataset_dir=/data/scripts/LES_TSI/SmallData/tfrecord/

python3 /home/sarah/Documents/Repository/Cloud-Base-Detection/eval.py --checkpoint_dir=/home/sarah/Documents/Repository/Cloud-Base-Detection/logdir/ --eval_logdir=/home/sarah/Documents/Repository/Cloud-Base-Detection/eval_logdir/ --dataset_dir=/data/scripts/LES_TSI/SmallData/tfrecord/

python3 /data/scripts/LES_TSI/sarahvtf.py --Masked=False --video_directory=/data/Renders/wrf_microhh/20160611_old/28800/ --folder=28800

Here is a note I copied and pasted from a website about a possible bug:
"Here is how I faced a similar error (Key aspp4_depthwise/BatchNorm/gamma not found in checkpoint), but seems for a different reason. I trained using atrous_rates=[6, 12, 18]. By mistake, I evaluated on atrous_rates=[6, 12, 18, 6, 12, 18]. Why the FLAGS list were duplicated? I accessed the FLAGS in the global section so params were evaluated twice (so be careful).

Side note for others in case helps: the code place where the key issue mistake happens is in: model.py - extract_features method - See line with text: scope = ASPP_SCOPE + str(i)

This scope asked for more entries (aspp4_*) that doesn't exist in the train model."
